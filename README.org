* Istio Hands-On for Kubernetes

My notes from the course on Udemy.
* What is Istio?
- [[https://thenewstack.io/how-does-service-discovery-work-in-kubernetes/][Service discovery mechanism]] in kubernetes allows network calls among containers
- Service Mesh replaces the kubernetes service communication mechanism
  - All network calls go through the service mesh layer
  - The service mesh can apply *mesh logic* before the request is routed to the target container or it could run after, or both
- What sorts of stuff happens in the service mesh layer?
  - Telemetry
  - Potentially rerouting requests based on certain requirements (sounds familiar)
- Istio injects a container to each pod
  - This container is called a proxy.  The ones I've seen are named =istio-proxy=
  - In istio, the proxies communicate with the mesh layer and the app container.  App containers don't talk directly to the mesh layer or each other.
- Istio's got all sorts of obtuse nautical names that make it harder to understand when you're a newb
- They simplified some of the nautical names to a single =istiod= daemon (it used to be called "pilot" ðŸ™„) that lives in the =istio-system= pod in your cluster
  - This is referred to as the "control plane"
  - Kiali is a user interface pod in the control plane. Presumably its name will make sense at some point.
- What changes do we need to make to our application containers to make this work?
  - None! (in theory)
  - There are some changes you need to make for tracing
  - TODO determine whether we are using this sort of tracing
* Hands on Istio demo
- Repo for the course https://github.com/DickChesterwood/istio-fleetman
** Getting istio running
(in the warmup-exercise directory)
*** Apply the manifests to install istio
    #+begin_src sh
      kubectl apply -f 1-istio-init.yaml
    #+end_src

Sets up a namespace and initializes a lot of stuff
*** To remove
    #+begin_src sh
      kubectl delete -f 1-istio-init.yaml
    #+end_src
*** Apply the manifests to start istio
    #+begin_src sh
      kubectl apply -f 2-istio-minikube.yaml
    #+end_src

Creates a bunch of deployments in the istio namespace
*** Install the Kiali secrets file
    #+begin_src sh
      kubectl apply -f 3-kiali-secret.yaml
    #+end_src

The username and password are base64 encoded.  You can decode them with

#+begin_src sh
  echo "YWRtaW4=" | base64 -d
#+end_src
*** Injecting the istio-proxy sidecar
The istio-proxy is injected into each pod in a namespace via the istiod based on the presence of a label in the namespace.

#+begin_src sh
  kubectl label namespace default istio-injection=enabled
#+end_src
To remove:
#+begin_src sh
  kubectl label namespace default istio-injection-
#+end_src

Whew this syntax is garbage.  Sort of like deleting a branch in git used to require colons in a special place.  Much easier to use the manifest :)

Istio uses init containers to do the injecting https://kubernetes.io/docs/concepts/workloads/pods/init-containers/ .  That explains the =Completed= =istio-init= we see when inspecting the containers within a pod.

*** Deploying up the application

#+begin_src sh
kubectl apply -f 4-application-full-stack.yaml
#+end_src

In order to visit the Fleet Manager web app, I am able to set up port forwarding for the webapp directly but I don't think that's going through istio.

*** How do I expose my webapp through istio so I can access it from localhost running in Kubernetes for Docker Desktop?
- I tried following https://istio.io/latest/docs/tasks/traffic-management/ingress/ingress-control/#determining-the-ingress-ip-and-ports
  - I determined that my ingress IP is 127.0.0.1 because I'm using Docker Desktop.
  - I determined that I needed to get the port from a =NodePort= because the =LoadBalancer='s external IP was stuck in a =<pending>= state.
  - I was not able to connect to the ingress successfully

- I'm going to take a step back and follow istios https://istio.io/latest/docs/setup/getting-started/ guide to determine whether the problem exists in the Udemy course's istio setup.
  - Still not successful.  The demo istio deployment has the same issue
  - Checked for any services running on conflicting ports, found one on port 80 and removed it
  - Was able to port forward the exposed nodeport from the pod running the ingressgateway, I get an empty response, but I can't talk to the application
  - Resetting kubernetes cluster seems to have done the trick! https://github.com/docker/for-mac/issues/4903
  - After following the steps in the getting started guide I got:

#+begin_src sh
  curl -I localhost/productpage
  HTTP/1.1 200 OK
  content-type: text/html; charset=utf-8
  content-length: 5183
  server: istio-envoy
  date: Fri, 28 Jan 2022 18:45:50 GMT
  x-envoy-upstream-service-time: 134
#+end_src

- When I revisit the example from the Udemy course

#+begin_src sh
  curl -I http://localhost:30080/
  HTTP/1.1 200 OK
  server: istio-envoy
  date: Fri, 28 Jan 2022 18:58:58 GMT
  content-type: text/html
  content-length: 816
  last-modified: Fri, 11 Oct 2019 19:15:44 GMT
  etag: "5da0d4e0-330"
  accept-ranges: bytes
  x-envoy-upstream-service-time: 0
  x-envoy-decorator-operation: fleetman-webapp.default.svc.cluster.local:80/*
#+end_src

which means it's working!

*** Finding perf problems
